# MUL
Machine unlearning, the process of selectively removing specific data points from a trained model while preserving general performance, has gained significant attention in privacy and security research. This paper presents an approach to machine unlearning in recurrent neural networks using a Gated Recurrent Unit (GRU)-based classifier trained on the MNIST dataset. We analyze the effects of unlearning a specific digit by filtering the dataset, retraining the model, and subsequently relearning the original dataset. Performance is evaluated using accuracy, loss curves, and layerwise distance metrics. Our results provide insights into the effectiveness of unlearning and the potential for adaptive machine learning models.
